\noindent In the following lines we explain very briefly how to correct for measurement error estimates from standard linear regressions estimated through OLS.\\\indent Let $y_{i}$ be a (demeaned) outcome of interest, $X_{i}$ be a (demeaned) vector of characteristics or controls, and $\mathbf{\theta}_{i}$ be a (demeaned) vector of factors.  $X_{i}$ is of dimension $1 \times K$ and  $\mathbf{\theta}_{i}$ is of dimension $1 \times K$. The objective is to estimate the coefficients in the following model\begin{equation}y_{i} = \mathbf{X_{i}}  \mathbf{\beta} + \mathbf{\theta}_{i} \mathbf{\gamma} + \varepsilon_{i} \label{eq:model}\end{equation}\noindent where $\mathbf{\beta}$ (vector) and $\mathbf{\gamma}$ (vector) are estimands and $ \mathbb{E}[ \varepsilon_{i} | \mathbf{X_{i}}, \mathbf{\theta}_{i}] = 0$.\\ \indent Plausibly, $\mathbf{\theta}_{i}$ is measured with error, since it is a factor score based on multiple measures arbitrarily chosen by the the researcher.\\\indent  \citet{croon2002using} proposes a correction. Let the relationship between the ``true factor scores'' and the ``estimated'' factor scores be given by\begin{equation}\hat{\mathbf{\theta_{i}}} = \mathbf{\theta_{i}} + V_{i} \label{eq:factor}\end{equation}\noindent where $\mathbb{E} \left[ V_{i} \right] = 0, \mathbb{E}[ V_{i} | \mathbf{X_{i}}, \mathbf{\theta}_{i}] = 0$. Let the convariance matrix of $\mathbf{R_{i}}$ and $\mathbf{S_{i}}$ be given by \begin{equation} \Sigma = \left[ \begin{array}{c c}    \Sigma_{\mathbf{R_{i}}, \mathbf{R_{i}}} & \Sigma_{\mathbf{R_{i}}, \mathbf{S_{i}}} \\    \Sigma_{\mathbf{S_{i}}, \mathbf{R_{i}}} &  \Sigma_{\mathbf{S_{i}}, \mathbf{S_{i}}}   \end{array}  \right].\end{equation}\indent If we assume \eqref{eq:model} is the data generating process, the OLS estimator is inconsistent. To see this substitute \eqref{eq:factor} into \eqref{eq:model} and obtain the following:\begin{equation}y_{i} = \beta_{0} + \mathbf{X_{i}}  \mathbf{\beta} + \mathbf{\theta_{i}} \mathbf{\gamma} + \varepsilon_{i} - \gamma V_{i} \label{eq:model}\end{equation} \noindent  so that \begin{equation}\plim  \left[ \begin{array}{c c}                   \hat{\beta}^{OLS} \\                    \hat{\gamma}^{OLS} \end{array} \right] = A\left[ \begin{array}{c c}                   \beta \\                   \gamma \end{array} \right]\end{equation}\noindent where $A = {\left[ \begin{array}{c c}    \Sigma_{\hat{\mathbf{\theta_{i}}} , \hat{\mathbf{\theta_{i}}} } & \Sigma_{\mathbf{\theta_{i}} , \mathbf{X_{i}}} \\    \Sigma_{\mathbf{X_{i}}, \mathbf{\theta_{i}}} &   \Sigma_{\mathbf{X_{i}}, \mathbf{X_{i}}}.   \end{array}  \right]}^{-1} {\left[ \begin{array}{c c}    \Sigma_{\mathbf{\theta_{i}} , \mathbf{\theta_{i}} } & \Sigma_{\mathbf{\theta_{i}} , \mathbf{X_{i}}} \\    \Sigma_{\mathbf{X_{i}}, \mathbf{\theta_{i}}} &  \Sigma_{\mathbf{X_{i}}, \mathbf{X_{i}}}.   \end{array}  \right]}$. Importantly \begin{eqnarray}\Sigma_{\hat{\mathbf{\theta_{i}}} , \hat{\mathbf{\theta_{i}}} } = \Sigma_{\mathbf{\theta_{i}} , \mathbf{\theta_{i}} } + \Sigma_{V_{i} , V_{i} }. \label{eq:hard}\end{eqnarray}\indent Now note that $\Sigma_{\mathbf{\theta_{i}} , \mathbf{X_{i}} } = \Sigma_{\hat{\mathbf{\theta_{i}}} , \mathbf{X_{i}} }$, so that we can estimate $a$. To get it straight, $\mathbf{\theta_{i}}$ is the vector of factor scores in the data. Thus, it's easy to obtain all the components in $A$ except for the component in \eqref{eq:hard}. They come from computing the empirical covariance matrices between the factor scores, $\mathbf{\theta_{i}}$, and the rest of the data in the estimation (controls), $\mathbf{X_{i}}$. To obtain $\Sigma_{\hat{\mathbf{\theta_{i}}} , \hat{\mathbf{\theta_{i}}} }$ calculate the variance of the factor scores, which depends on the factor extraction method. Once all the components of $A$ have been estimated, premultiplying the OLS estimates by its inverse yields consistent estimates:\begin{equation}A ^{-1} \plim  \left[ \begin{array}{c c}                   \hat{\beta}^{OLS} \\                    \hat{\gamma}^{OLS} \end{array} \right] = \left[ \begin{array}{c c}                   \beta \\                   \gamma \end{array} \right].\end{equation}\indent Put differently, premultiplying the OLS estimates by $A^{-1}$ is Croon's correction.